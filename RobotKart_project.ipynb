{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#########################################################################\n",
    "#Project Name: RoboKart: Robot-assisted Grocery Shopping\n",
    "#Authors Name: Anja Gross, Gunjan Gupta\n",
    "#Date: 16-07-2020\n",
    "#Machine Learning and Robotics Lab, University of Stuttgart, Germany\n",
    "#########################################################################\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import sys\n",
    "sys.path.append('../../build')\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import libry as ry\n",
    "import time\n",
    "import math\n",
    "import PySimpleGUI as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration file along with the configuration viewer\n",
    "RealWorld = ry.Config()\n",
    "RealWorld.addFile(\"../../scenarios/pandasTable_modified.g\")\n",
    "V = ry.ConfigurationViewer()\n",
    "V.setConfiguration(RealWorld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up the shelf on the left hand side of the robot \n",
    "l_shelf = RealWorld.addFrame(\"l_shelf\")\n",
    "l_shelf.setShape(ry.ST.ssBox, [0.3, 2., 0.6, 0.02])\n",
    "l_shelf.setColor([0.6, 0.298, 0])\n",
    "l_shelf.setPosition([-0.7, 0.0, 1.0])\n",
    "    \n",
    "# Sets up the shelf on the right hand side of the robot \n",
    "r_shelf = RealWorld.addFrame(\"r_shelf\")\n",
    "r_shelf.setShape(ry.ST.ssBox, [0.3, 2., 0.6, 0.02])\n",
    "r_shelf.setColor([0.6, 0.298, 0])\n",
    "r_shelf.setPosition([0.7, 0.0, 1.0])\n",
    "\n",
    "#places the obstacle for collision detection\n",
    "obstacle = RealWorld.addFrame(\"obstacle\")\n",
    "obstacle.setShape(ry.ST.ssBox, [0.1, 0.1, 0.5, 0.02])\n",
    "obstacle.setPosition([0.2, 3.5, 1.0])\n",
    "obstacle.setColor([1.0, 0.0, 0.0])\n",
    "\n",
    "#objects available for shopping\n",
    "itemNames = {\n",
    "    \n",
    "    \"blue\" : [\"blue1\",\"blue2\",\"blue3\",\"blue4\"],\n",
    "    \"red\" : [\"red1\", \"red2\",\"red3\"],\n",
    "    \"green\" : [\"green1\", \"green2\",\"green3\"]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object creation\n",
    "def createItem(name, color, pos):\n",
    "    name = RealWorld.addFrame(name)\n",
    "    colorVal = []\n",
    "    \n",
    "    if color == \"blue\":\n",
    "        name.setShape(ry.ST.ssBox, [0.1, 0.1, 0.1, .02])\n",
    "        colorVal = [0,0,1]\n",
    "    elif color == \"red\":\n",
    "        name.setShape(ry.ST.sphere, [0.05, 0.05, 0.05])\n",
    "        colorVal = [1,0,0]\n",
    "    elif color == \"green\":\n",
    "        name.setShape(ry.ST.capsule, [0.05,0.06,0.04])\n",
    "        colorVal = [0,1,0]\n",
    "\n",
    "    name.setPosition(pos)\n",
    "    name.setColor(colorVal) \n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<libry.CameraViewSensor at 0x7fce826c08b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add cameras\n",
    "\n",
    "# Right camera, looking at the right shelf\n",
    "f_r_camera = RealWorld.frame(\"r_camera\")\n",
    "\n",
    "# Left camera, looking at the left shelf\n",
    "f_l_camera = RealWorld.frame(\"l_camera\")\n",
    "\n",
    "# Cart camera, sitting in front of the cart and facing what is in front of the cart\n",
    "f_cart_camera = RealWorld.frame(\"cart_camera\")\n",
    "V.setConfiguration(RealWorld)\n",
    "\n",
    "S = RealWorld.simulation(ry.SimulatorEngine.physx, True)\n",
    "S.addSensor(\"r_camera\")\n",
    "S.addSensor(\"l_camera\")\n",
    "S.addSensor(\"cart_camera\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The camera parameters of all three cameras.\n",
    "f = 0.895\n",
    "f = f * 260.\n",
    "fxfypxpy = [f, f, 320., 180.]\n",
    "\n",
    "# save initial background\n",
    "[rgb0, depth0] = S.getImageAndDepth()  #we don't need images with 100Hz, rendering is slow\n",
    "points0 = S.depthData2pointCloud(depth0, fxfypxpy)\n",
    "\n",
    "#creating empty objects, later used for grasping, in collision detection\n",
    "obj = RealWorld.addFrame(\"object\")\n",
    "obj_obstacle = RealWorld.addFrame(\"objobstacle\")\n",
    "obj_gripper = RealWorld.addFrame(\"object_gripper\")\n",
    "targetObj = RealWorld.addFrame(\"targetdes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the tau value that decides the smoothness of the robot motion\n",
    "tau = 0.01\n",
    "komo = RealWorld.komo_IK(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for opening the gripper for aligning and grasping the object\n",
    "def openGripper():\n",
    "    print('                  Opening                   ')\n",
    "    print('--------------------------------------------')\n",
    "    S.openGripper(\"L_gripper\")\n",
    "    while S.getGripperWidth(\"L_gripper\") < 0.06: \n",
    "        time.sleep(tau)\n",
    "        S.step([], tau, ry.ControlMode.none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for aligning the gripper with respect to the orientation of the object for grasping and picking\n",
    "def align(p_o, itemAlign, selCamera):\n",
    "    print('                 Aligning                   ')\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    #align the gripper wrt to the cart for pushing it\n",
    "    if itemAlign == \"shopcart\":\n",
    "        p_o[1] = p_o[1] - 0.50\n",
    "    for t in range(300):\n",
    "        if S.getGripperIsGrasping(\"L_gripper\"): break\n",
    "        time.sleep(tau)\n",
    "        q = S.get_q()\n",
    "        obj.setPosition(p_o)\n",
    "\n",
    "        #compute a target robot pose using optimization\n",
    "        RealWorld.setJointState(q)\n",
    "        V.setConfiguration(RealWorld)\n",
    "        komo = RealWorld.komo_path(1.,1,tau, True)\n",
    "        komo.clearObjectives()\n",
    "        komo.add_qControlObjective(order = 1, scale = 1e0)\n",
    "        komo.addObjective([], ry.FS.accumulatedCollisions, type = ry.OT.ineq, scale = [1e2])\n",
    "        \n",
    "        #align the gripper wrt to the object for grasping and picking it\n",
    "        if itemAlign == \"objects\":\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductXX, frames=['L_gripperCenter', 'object'], target=[-1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYY, frames=['L_gripperCenter', 'object'], target=[-1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductZZ, frames=['L_gripperCenter', 'object'], target=[1])\n",
    "            komo.addObjective([], ry.FS.vectorZ, [\"L_gripperCenter\"], ry.OT.sos, scale=[1e1], target=[0,0,1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.positionDiff, frames=['L_gripperCenter', 'object'], scale=[1e2], target=[0.0,0.0,0.2])\n",
    "\n",
    "        else:  #Komo objectives to align with respect to the cart\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductXX, frames=['L_gripperCenter', 'object'], target=[0])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYY, frames=['L_gripperCenter', 'object'], target=[0])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductZZ, frames=['L_gripperCenter', 'object'], target=[0])\n",
    "            \n",
    "            if selCamera == \"lcam\": #alignment for the cart wrt to the left camera\n",
    "                komo.addObjective([], ry.FS.vectorX, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,-1])\n",
    "            else: #alignment for the cart wrt to the right camera\n",
    "                komo.addObjective([], ry.FS.vectorX, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.positionDiff, frames=['L_gripperCenter', 'object'], scale=[1e2], target=[0.0,-0.1,0.0])\n",
    "            \n",
    "        #keep gripper open\n",
    "        komo.addObjective([], ry.FS.qItself, [\"L_finger1\"], ry.OT.eq, [1e1], order = 1)\n",
    "\n",
    "        #add limit on velocity\n",
    "        vel_lim = 100.\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [1e1], target=[vel_lim]*8, order = 1)\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [-1e1], target=[-vel_lim]*8, order = 1)\n",
    "\n",
    "        komo.optimize()\n",
    "        RealWorld.setFrameState(komo.getConfiguration(0))\n",
    "        q = RealWorld.getJointState()\n",
    "\n",
    "        #send controls to the simulation\n",
    "        S.step(q, tau, ry.ControlMode.position)\n",
    "\n",
    "    obj_gripper.setPosition(RealWorld.getFrame(\"L_gripperCenter\").getPosition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to grasp the objects \n",
    "def grasp(itemGrasp, selGraspCamera):\n",
    "    print('                 Grasping                   ')\n",
    "    print('--------------------------------------------')\n",
    "    closing = False\n",
    "    errPer, errCon = np.inf, np.inf\n",
    "    while True:\n",
    "        if S.getGripperIsGrasping(\"L_gripper\"): break\n",
    "        time.sleep(tau)\n",
    "        q = S.get_q()\n",
    "        \n",
    "        #decide on grasp?\n",
    "        if not closing:\n",
    "            [y,J] = RealWorld.evalFeature(ry.FS.positionDiff, [\"L_gripperCenter\", \"object\"])\n",
    "            errCon = np.abs(y).max()\n",
    "            print(errCon)\n",
    "            if errCon < 0.02:\n",
    "                print('--------------------------------------------')\n",
    "                print('       Closing the gripper                  ')\n",
    "                print('--------------------------------------------')\n",
    "                closing = True\n",
    "                S.closeGripper(\"L_gripper\")\n",
    "\n",
    "        #compute a target robot pose using optimization\n",
    "        RealWorld.setJointState(q)\n",
    "        V.setConfiguration(RealWorld)\n",
    "        komo = RealWorld.komo_path(1.,1,tau, True)\n",
    "        komo.clearObjectives()\n",
    "        komo.add_qControlObjective(order = 1, scale = 1e0)\n",
    "        komo.addObjective([], ry.FS.accumulatedCollisions, type = ry.OT.ineq, scale = [1e2])\n",
    "        \n",
    "        if itemGrasp == \"objects\": #komo objectives to grasp the objects\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductXX, frames=['L_gripperCenter', 'object'], target=[-1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYY, frames=['L_gripperCenter', 'object'], target=[-1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductZZ, frames=['L_gripperCenter', 'object'], target=[1])\n",
    "            komo.addObjective([], ry.FS.vectorZ, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.positionDiff, frames=['L_gripperCenter', 'object'], scale=[1e2], target=[0.0,0.0,0.02])\n",
    "        else: #komo objectives to grasp the shopping cart\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductXX, frames=['L_gripperCenter', 'object'], target=[0])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYY, frames=['L_gripperCenter', 'object'], target=[0])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductZZ, frames=['L_gripperCenter', 'object'], target=[0])\n",
    "            \n",
    "            if selGraspCamera == \"lcam\": #objectives for the cart wrt to the left camera (when objects are only picked from the left shelf)\n",
    "                komo.addObjective([], ry.FS.vectorX, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,-1])\n",
    "            else: #objectives for the cart wrt to the right camera (when objects are picked from the right shelf)\n",
    "                komo.addObjective([], ry.FS.vectorX, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,1])\n",
    "            komo.addObjective(type=ry.OT.eq, feature=ry.FS.positionDiff, frames=['L_gripperCenter', 'object'], scale=[1e2], target=[0.0,0.02,0.0])\n",
    "        #keep gripper open\n",
    "        komo.addObjective([], ry.FS.qItself, [\"L_finger1\"], ry.OT.eq, [1e1], order = 1)\n",
    "\n",
    "        #add limit on velocity\n",
    "        vel_lim = 100.\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [1e1], target=[vel_lim]*8, order = 1)\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [-1e1], target=[-vel_lim]*8, order = 1)\n",
    "\n",
    "        komo.optimize()\n",
    "        RealWorld.setFrameState(komo.getConfiguration(0))\n",
    "        q = RealWorld.getJointState()\n",
    "\n",
    "        #send controls to the simulation\n",
    "        S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to lift the object after grasping from the shelf\n",
    "def lift():\n",
    "    print('                Lifting                     ')\n",
    "    print('--------------------------------------------')\n",
    "    errPer, errCon = np.inf, np.inf\n",
    "    \n",
    "    for t in range(100):\n",
    "        time.sleep(tau)\n",
    "        q = S.get_q()\n",
    "\n",
    "        #compute a target robot pose using optimization\n",
    "        RealWorld.setJointState(q)\n",
    "        V.setConfiguration(RealWorld)\n",
    "        komo = RealWorld.komo_path(1.,1,tau, True)\n",
    "        komo.clearObjectives()\n",
    "        komo.add_qControlObjective(order = 1, scale = 1e0)\n",
    "        #komo objectives for lifting the objects (from either shelf)\n",
    "        komo.addObjective([], ry.FS.accumulatedCollisions, type = ry.OT.ineq, scale = [1e2])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductXX, frames=['L_gripperCenter', 'object_gripper'], target=[-1])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYY, frames=['L_gripperCenter', 'object_gripper'], target=[-1])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductZZ, frames=['L_gripperCenter', 'object_gripper'], target=[1])\n",
    "        komo.addObjective([], ry.FS.vectorZ, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,1])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.positionDiff, frames=['L_gripperCenter', 'object_gripper'], scale=[1e2], target=[0.0,0.0,0.1])\n",
    "\n",
    "        #keep gripper open\n",
    "        komo.addObjective([], ry.FS.qItself, [\"L_finger1\"], ry.OT.eq, [1e1], order = 1)\n",
    "\n",
    "        #add limit on velocity\n",
    "        vel_lim = 100.\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [1e1], target=[vel_lim]*8, order = 1)\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [-1e1], target=[-vel_lim]*8, order = 1)\n",
    "\n",
    "        komo.optimize()\n",
    "        RealWorld.setFrameState(komo.getConfiguration(0))\n",
    "        q = RealWorld.getJointState()\n",
    "\n",
    "        #send controls to the simulation\n",
    "        S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to truncate the digits to obtain the position of the object/obstacle (obtained using perception) upto the specified digits\n",
    "def truncate(num, digits):\n",
    "    stepper = 10.0 ** digits\n",
    "    return math.trunc(stepper * num)/stepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to place the objects on the cart after lifting them\n",
    "def place(num):\n",
    "    print('                Placing                     ')\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    #specify the position of placing on the cart based on the color, so that objects of the same color are placed together\n",
    "    if num == 0:\n",
    "        targetObj.setPosition([0.20, 0.35, 1.4]) #position of red object on the cart\n",
    "    elif num == 1:\n",
    "        targetObj.setPosition([0.20, 0.20, 1.6]) #position of green object on the cart\n",
    "    else:\n",
    "        targetObj.setPosition([-0.35, 0.40, 1.6]) #position of blue object on the cart\n",
    "\n",
    "    for t in range(100):\n",
    "        time.sleep(tau)            \n",
    "        q = S.get_q()\n",
    "\n",
    "        #compute a target robot pose using optimization\n",
    "        RealWorld.setJointState(q)\n",
    "        V.setConfiguration(RealWorld)\n",
    "        komo = RealWorld.komo_path(1.,1,tau, True)\n",
    "        komo.clearObjectives()\n",
    "        komo.add_qControlObjective(order = 1, scale = 1e0)\n",
    "        #komo objectives for placing the objects on the cart\n",
    "        komo.addObjective([], ry.FS.accumulatedCollisions, type = ry.OT.ineq, scale = [1e2])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductXX, frames=['L_gripperCenter', 'targetdes'], target=[-1])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductYY, frames=['L_gripperCenter', 'targetdes'], target=[-1])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.scalarProductZZ, frames=['L_gripperCenter', 'targetdes'], target=[1])\n",
    "        komo.addObjective([], ry.FS.vectorZ, [\"L_gripperCenter\"], ry.OT.eq, scale=[1e1], target=[0,0,1])\n",
    "        komo.addObjective(type=ry.OT.eq, feature=ry.FS.positionDiff, frames=['L_gripperCenter', 'targetdes'], scale=[1e2], target=[0.0,0.0,0.0])\n",
    "\n",
    "        #keep gripper open\n",
    "        komo.addObjective([], ry.FS.qItself, [\"L_finger1\"], ry.OT.eq, [1e1], order = 1)\n",
    "\n",
    "        #add limit on velocity\n",
    "        vel_lim = 100.\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [1e1], target=[vel_lim]*8, order = 1)\n",
    "        komo.addObjective([], ry.FS.qItself, [], ry.OT.ineq, [-1e1], target=[-vel_lim]*8, order = 1)\n",
    "\n",
    "        komo.optimize()\n",
    "        RealWorld.setFrameState(komo.getConfiguration(0))\n",
    "        q = RealWorld.getJointState()\n",
    "\n",
    "        #send controls to the simulation\n",
    "        S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to display the color of the items on the shelf as a list\n",
    "def cvfunc(colorlist):\n",
    "    cols=[]\n",
    "    templist= 0\n",
    "    for i in range(len(colorlist)):\n",
    "        j=0\n",
    "        templist=colorlist[i]\n",
    "        while j< templist:\n",
    "            if i == 0:\n",
    "                cols.append(\"red\")\n",
    "            elif i==1:\n",
    "                cols.append(\"green\")\n",
    "            else:\n",
    "                cols.append(\"blue\")\n",
    "    \n",
    "            j = j+ 1\n",
    "    return cols    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the main method responsible for shoppping (all logic written in this method)\n",
    "def shopping(itemCol, itemNum, maxItems):\n",
    "    print('--------------------------------------------')\n",
    "    print('                 Shopping                   ')\n",
    "    temp = 0\n",
    "    flagleft= False\n",
    "    flagright= False\n",
    "    redundant_items= 0\n",
    "    robotPos = \"center\"  #initially the robot's position will be at the center\n",
    "    #to check if the shopping cart is empty\n",
    "    if maxItems==0:\n",
    "        print('    Please add items into the cart          ')\n",
    "        print('--------------------------------------------')\n",
    "        sg.Popup(\"Cart is empty!\",font=(\"ComicSansMS\", 12),button_color=('Black', 'White'),button_type=4)\n",
    "    else:\n",
    "        #the robot first moves to the left shelf\n",
    "        moveRobot1(-0.25)\n",
    "        robotPos = \"left\"\n",
    "        initialLeftJointState = RealWorld.getJointState()\n",
    "        #color segmentation to display the object colors on the left shelf as a list \n",
    "        colList = colorSeg(\"lcam\")\n",
    "        cols = cvfunc(colList)\n",
    "        print('     Starting with the Left shelf           ')\n",
    "        print('--------------------------------------------')\n",
    "\n",
    "        # For Left Shelf\n",
    "        for k in range(len(itemCol)):\n",
    "            flagleft = False\n",
    "            if itemNum[k] != 0:\n",
    "                for j in range(len(cols)):\n",
    "                    if itemCol[k] == cols[j]:\n",
    "                        flagleft= True\n",
    "                        #checking for the red objects\n",
    "                        if cols[j] == \"red\":\n",
    "                            itemColor[0] = \"red\"\n",
    "                            itemcount = 0\n",
    "                            #responsible for Perception to provide the position (x-y-z) coorindates of the object that needs to be shopped.\n",
    "                            doItemPerception(\"camera_l\")\n",
    "                            #method to get the coordinates of the perceived object from the left camera\n",
    "                            arr = getObjPointPos(\"camera_l\", \"red\")\n",
    "                            m = len(arr)\n",
    "                            while itemcount < m:\n",
    "                                arr[itemcount] = truncate(arr[itemcount],3)   \n",
    "                                itemcount = itemcount + 1\n",
    "                            #adding offset to the perceived position\n",
    "                            arr[0]= arr[0] + 0.069 # along x axis\n",
    "                            arr[1]= arr[1] + 0.010 # along y axis\n",
    "                            arr[2]= arr[2] - 0.030 # along z axis\n",
    "                            p_obj = arr\n",
    "                            number = 0\n",
    "                        #checking for the green objects\n",
    "                        elif cols[j] == \"green\":\n",
    "                            itemColor[0] = \"green\"\n",
    "                            itemcount = 0\n",
    "                            doItemPerception(\"camera_l\")\n",
    "                            arr = getObjPointPos(\"camera_l\", \"green\")\n",
    "                            m = len(arr)\n",
    "                            while itemcount < m:\n",
    "                                arr[itemcount] = truncate(arr[itemcount],3)   \n",
    "                                itemcount = itemcount + 1\n",
    "                            arr[0]= arr[0] + 0.069 # along x axis\n",
    "                            arr[1]= arr[1] + 0.010 # along y axis\n",
    "                            arr[2]= arr[2] + 0.014 # along z axis\n",
    "                            p_obj = arr\n",
    "                            number = 1\n",
    "                        #checking for the blue objects\n",
    "                        else:\n",
    "                            itemColor[0] = \"blue\"\n",
    "                            itemcount = 0\n",
    "                            doItemPerception(\"camera_l\")\n",
    "                            arr = getObjPointPos(\"camera_l\", \"blue\")\n",
    "                            m = len(arr)\n",
    "                            while itemcount < m:\n",
    "                                arr[itemcount] = truncate(arr[itemcount],3)   \n",
    "                                itemcount = itemcount + 1\n",
    "                            arr[0]= arr[0] + 0.069 # along x axis\n",
    "                            arr[1]= arr[1] + 0.13 # along y axis\n",
    "                            arr[2]= arr[2] - 0.023 # along z axis\n",
    "                            p_obj = arr\n",
    "                            number = 2\n",
    "\n",
    "                        openGripper()\n",
    "                        align(p_obj, \"objects\", \"lcam\")\n",
    "                        grasp(\"objects\", \"lcam\")\n",
    "                        lift()\n",
    "                        place(number)\n",
    "                        openGripper()\n",
    "                        RealWorld.setJointState(initialLeftJointState) #this makes the robot to go back to its initial joint state after placing each object on the cart\n",
    "                        itemNum[k] = itemNum[k] - 1\n",
    "                        temp = temp + 1\n",
    "                    #to check if shopping is completed for a particular color-object before proceeding to the right shelf\n",
    "                    if itemNum[k] == 0:\n",
    "                        print('Shopping is done for {}' .format(itemCol[k]))\n",
    "                        print('-------------------------------------------')\n",
    "                        break\n",
    "                #to check if an object of a different color (other then red, blue or green) is desired to be shopped- through the user input from GUI\n",
    "                if flagleft== False:\n",
    "                    print('Item {} not found in the left shelf!'.format(itemCol[k])) #to print on the console\n",
    "                    sg.Popup(\"Item unavailable on the left shelf!\",font=(\"ComicSansMS\", 12),button_color=('Black', 'White'),button_type=4)\n",
    "        #RealWorld.setJointState(initialLeftJointState)\n",
    "        print('             Left shelf done              ')\n",
    "        print('------------------------------------------')\n",
    "        if temp != maxItems:  # To check whether we need to go to right shelf or not\n",
    "            print('       Continuing with the Right shelf      ')\n",
    "            #after the robot has picked all the objects it could have from the left shelf, it moves to the right shelf and performs the same functionality as above\n",
    "            moveRobot1(0.50)\n",
    "            robotPos = \"right\"\n",
    "            initialRightJointState = RealWorld.getJointState()\n",
    "\n",
    "        while temp != maxItems:  # To check whether we need to go to right shelf or not\n",
    "            print('       Continuing with the Right shelf      ')\n",
    "            print('--------------------------------------------')\n",
    "            colList= colorSeg(\"rcam\")\n",
    "            cols = cvfunc(colList)\n",
    "            for k in range(len(itemCol)):\n",
    "                flagright= False\n",
    "                if itemNum[k] != 0:\n",
    "                    for j in range(len(cols)):\n",
    "                        if itemCol[k] == cols[j]:\n",
    "                            flagright = True\n",
    "                            #checking for red objects\n",
    "                            if cols[j] == \"red\":\n",
    "                                itemColor[0] = \"red\"\n",
    "                                itemcount = 0\n",
    "                                doItemPerception(\"camera_r\")\n",
    "                                #method to get the coordinates of the perceived object from the right camera\n",
    "                                arr = getObjPointPos(\"camera_r\", \"red\")\n",
    "                                m = len(arr)\n",
    "                                while itemcount < m:\n",
    "                                    arr[itemcount] = truncate(arr[itemcount],3)   \n",
    "                                    itemcount = itemcount + 1\n",
    "                                arr[0]= arr[0] - 0.069 # along x axis\n",
    "                                arr[1]= arr[1] + 0.03 # along y axis\n",
    "                                arr[2]= arr[2] - 0.033 # along z axis\n",
    "                                p_obj = arr\n",
    "                                number = 0\n",
    "                            #checking for green objects\n",
    "                            elif cols[j] == \"green\":\n",
    "                                itemColor[0] = \"green\"\n",
    "                                itemcount = 0\n",
    "                                doItemPerception(\"camera_r\")\n",
    "                                arr = getObjPointPos(\"camera_r\", \"green\")\n",
    "                                m = len(arr)\n",
    "                                while itemcount < m:\n",
    "                                    arr[itemcount] = truncate(arr[itemcount],3)   \n",
    "                                    itemcount = itemcount + 1\n",
    "                                arr[0]= arr[0] - 0.069 # along x axis\n",
    "                                arr[1]= arr[1] + 0.130 # along y axis\n",
    "                                arr[2]= arr[2] + 0.014 # along z axis\n",
    "                                p_obj = arr\n",
    "                                number = 1\n",
    "                            #checking for the blue objects\n",
    "                            else:\n",
    "                                itemColor[0] = \"blue\"\n",
    "                                itemcount = 0\n",
    "                                doItemPerception(\"camera_r\")\n",
    "                                arr = getObjPointPos(\"camera_r\", \"blue\")\n",
    "                                m = len(arr)\n",
    "                                while itemcount < m:\n",
    "                                    arr[itemcount] = truncate(arr[itemcount],3)   \n",
    "                                    itemcount = itemcount + 1\n",
    "                                arr[0]= arr[0] - 0.069 # along x axis\n",
    "                                arr[1]= arr[1] + 0.030 # along y axis\n",
    "                                arr[2]= arr[2] - 0.030 # along z axis\n",
    "                                p_obj = arr\n",
    "                                number = 2\n",
    "\n",
    "                            openGripper()\n",
    "                            align(p_obj, \"objects\", \"rcam\")\n",
    "                            grasp(\"objects\", \"rcam\")\n",
    "                            lift()\n",
    "                            place(number)\n",
    "                            openGripper()\n",
    "                            RealWorld.setJointState(initialRightJointState)\n",
    "                            itemNum[k] = itemNum[k] - 1\n",
    "                            temp = temp + 1\n",
    "\n",
    "                        #to check if shopping is completed for a particular color-object after picking the objects from the right shelf\n",
    "                        if itemNum[k] == 0:\n",
    "                            print('Shopping is done for {}' .format(itemCol[k]))\n",
    "                            print('-------------------------------------------')\n",
    "                            break\n",
    "                     #to check if an object of a different color (other then red, blue or green) is desired to be shopped- through the user input from GUI\n",
    "                    if flagright== False:\n",
    "                        print('Item {} not found in the right shelf!'.format(itemCol[k])) #to display on the terminal.\n",
    "                        sg.Popup(\"Item unavailable on the right shelf!\",font=(\"ComicSansMS\", 12),button_color=('Black', 'White'),button_type=4)\n",
    "                        temp=temp + itemNum[k]\n",
    "                        redundant_items = itemNum[k]\n",
    "\n",
    "        print('             Right shelf done               ')\n",
    "        print('--------------------------------------------')\n",
    "#         if robotPos == \"right\":\n",
    "#             RealWorld.setJointState(initialRightJointState)\n",
    "\n",
    "    # writing the updated list into the file\n",
    "    for i in range(0, len(itemNum)):\n",
    "        itemNum[i] = str(itemNum[i])\n",
    "    itemNum= [' {0} '.format(elem)for elem in itemNum]\n",
    "    list= np.char.add(itemCol, itemNum)\n",
    "\n",
    "    with open('shoppingList.txt','w') as f:\n",
    "        for item in list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    #cart motion started after the shopping is completed and all objects to be picked are placed on the cart.\n",
    "    if(maxItems-redundant_items!=0):\n",
    "        print('             Cart Motion started            ')\n",
    "        print('--------------------------------------------')\n",
    "        p_obj = RealWorld.getFrame(\"cart\").getPosition()\n",
    "        if robotPos == \"left\":\n",
    "            posCam = \"lcam\"\n",
    "        elif robotPos == \"right\":\n",
    "            posCam = \"rcam\"\n",
    "        else:\n",
    "            print(\"Cart position is not proper to push\")\n",
    "        openGripper()\n",
    "        align(p_obj,\"shopcart\", posCam)\n",
    "        grasp(\"shopcart\", posCam)\n",
    "        pushCart()\n",
    "        print('             Shopping completed             ')\n",
    "        print('--------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for robot motion using step function\n",
    "def moveRobot1(limit):\n",
    "    print('--------------------------------------------')\n",
    "    print('                 Moving Robot               ')\n",
    "    print('--------------------------------------------')\n",
    "    linkPos = RealWorld.frame(\"L_panda_link0\")\n",
    "    linkTemp = linkPos.getPosition()\n",
    "    linkPos.setPosition([linkTemp[0]+limit, linkTemp[1], linkTemp[2]])\n",
    "    q = S.get_q()\n",
    "    S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for robot to push the cart after it aligns and grasps its gripper wrt to the cart\n",
    "def pushCart():\n",
    "    print('            Pushing the cart now!           ')\n",
    "    print('--------------------------------------------')\n",
    "    nearing = False\n",
    "    end = False\n",
    "    linkPos = RealWorld.frame(\"L_panda_link0\")\n",
    "    cartPos = RealWorld.frame(\"cart\")\n",
    "    #the camera on the cart perceives any obstacle, if any along the robot's path \n",
    "    doItemPerception(\"camera_cart\")\n",
    "    #method to get the coordinates of the obstacle perceived from the cart camera\n",
    "    arr= getObstaclePos()\n",
    "    m = len(arr)\n",
    "    itemcount = 0\n",
    "    while itemcount < m:\n",
    "        arr[itemcount] = truncate(arr[itemcount],1)   \n",
    "        itemcount = itemcount + 1\n",
    "    obj_obstacle.setPosition(arr)\n",
    "    while True:\n",
    "        time.sleep(tau)\n",
    "        linkTemp = linkPos.getPosition()\n",
    "        #obstacle detection\n",
    "        if not nearing:\n",
    "            [y,J] = RealWorld.evalFeature(ry.FS.positionDiff, [\"cart\", \"objobstacle\"])\n",
    "            errCon = np.abs(y).max()\n",
    "            if errCon < 0.70: \n",
    "                print('            Obsatcle Detection!           ')\n",
    "                print('------------------------------------------')\n",
    "                nearing = True\n",
    "                #collision avoidance by altering the robot path to turn to the left after detecting an obstacle.\n",
    "                pushLeftCart()\n",
    "                linkTemp = linkPos.getPosition()\n",
    "       #end position for the robot to stop wrt to the table end position\n",
    "        if not end:\n",
    "            [y,J] = RealWorld.evalFeature(ry.FS.positionDiff, [\"cart\", \"table\"])\n",
    "            errCon1 = np.abs(y).max()\n",
    "            if errCon1 > 2.5: \n",
    "                print('            The End!                      ')\n",
    "                print('------------------------------------------')\n",
    "                end = True\n",
    "                break\n",
    "\n",
    "        linkPos.setPosition([linkTemp[0], linkTemp[1]+0.0005, linkTemp[2]])\n",
    "        q = S.get_q()\n",
    "        S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for the robot to shift the position of the cart to left, after it detects an obstacle\n",
    "def pushLeftCart():\n",
    "    print('            Avoiding Obstacle!            ')\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    linkPos = RealWorld.frame(\"L_panda_link0\")\n",
    "\n",
    "    for t in range(1000):\n",
    "        time.sleep(tau)\n",
    "        linkTemp = linkPos.getPosition()\n",
    "        linkPos.setPosition([linkTemp[0]-0.0005, linkTemp[1], linkTemp[2]])\n",
    "        q = S.get_q()\n",
    "        S.step(q, tau, ry.ControlMode.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block includes the working of perception- to obtain the position of the objects on the shelf or the cart real-time.\n",
    "objPos_r = np.zeros(shape=(360,640,3)) #position of the object on the left shelf\n",
    "objPos_l = np.zeros(shape=(360,640,3)) #position of the object on the right shelf\n",
    "objPos_cart = np.zeros(shape=(360,640,3)) #position of the obstacle wrt to the cart camera\n",
    "\n",
    "itemColor = [0] * 1\n",
    "#default color\n",
    "itemColor[0] = \"\"\n",
    "\n",
    "objPosPoint = np.zeros(3)\n",
    "objPosPoint_r = np.zeros(3)\n",
    "objPosPoint_l = np.zeros(3)\n",
    "objPosPoint_cart = np.zeros(3)\n",
    "objPoints_r = None\n",
    "objPoints_l = None\n",
    "\n",
    "bgr = None\n",
    "\n",
    "\n",
    "# Retrieves the mean point of all the points of the most right positioned object of a given colour in the given camera image (x, y, z coordinates) in world frame.\n",
    "def getObjPointPos(camera, colorName):\n",
    "    itemColor[0] = colorName\n",
    "\n",
    "    if camera == \"camera_r\":\n",
    "        return objPosPoint_r\n",
    "    elif camera == \"camera_l\":\n",
    "        return objPosPoint_l\n",
    "\n",
    "    \n",
    "# Retrieves the mean point of all the points of the obstacle in front of the cart in the picture of the cart camera (x, y, z coordinates) in world frame\n",
    "def getObstaclePos():\n",
    "    return objPosPoint_cart\n",
    "\n",
    "# Gets the images of the right, the left and the cart camera.\n",
    "# Sets the mean position of all the points of the most right object of the current itemColor to the left and the right camera.\n",
    "# Sets the mean position of all the points of the obstacle.\n",
    "def doItemPerception(camera):\n",
    "\n",
    "    points = []\n",
    "    tau = .01\n",
    "\n",
    "    fertig = False  \n",
    "\n",
    "    for t in range(100):\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        #grab sensor readings from the simulation\n",
    "        q = S.get_q()\n",
    "        if t%10 == 0:\n",
    "            if camera == \"camera_r\":\n",
    "                # Images from right camera\n",
    "                S.selectSensor(\"r_camera\")\n",
    "                [rgb, depth] = S.getImageAndDepth()\n",
    "                #global bgr\n",
    "                bgr = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
    "                hsv = cv.cvtColor(bgr, cv.COLOR_BGR2HSV)          \n",
    "\n",
    "                # Gets the points of the depth picture of the selected camera\n",
    "                points = S.depthData2pointCloud(depth, fxfypxpy)\n",
    "                \n",
    "                # This is accessing the global objPos_r variable! Otherwise it would create a local one instead\n",
    "                global objPosPoint_r\n",
    "                masked, p_obj_rel = findObjPointPos(hsv, depth)\n",
    "\n",
    "                # Cooordinate conversion from camera frame to world frame\n",
    "                obj = RealWorld.addFrame(\"object\", \"r_camera\")\n",
    "                obj.setRelativePosition(p_obj_rel)\n",
    "                p_obj_world = obj.getPosition()\n",
    "                objPosPoint_r = p_obj_world\n",
    "                \n",
    "                 # Attach the point cloud to the rbg/bgr image (IMPORTANT: can only be seen in configuration space,\n",
    "                 # where rgb holds vs. in cv bgr is used. So blue and red are swapped!)            \n",
    "                 #r_cameraFrame.setPointCloud(objPosPoint_r, bgr)\n",
    "           \n",
    "            \n",
    "            elif camera == \"camera_l\":\n",
    "                # Images from left camera\n",
    "                S.selectSensor(\"l_camera\")\n",
    "                [rgb, depth] = S.getImageAndDepth()\n",
    "                bgr = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
    "                hsv = cv.cvtColor(bgr, cv.COLOR_BGR2HSV)\n",
    "\n",
    "                global objPosPoint_l\n",
    "                masked, p_obj_rel = findObjPointPos(hsv, depth)\n",
    "\n",
    "                # Coordinate conversion from camera frame to world frame\n",
    "                obj = RealWorld.addFrame(\"object\", \"l_camera\")\n",
    "                obj.setRelativePosition(p_obj_rel)\n",
    "                p_obj_world = obj.getPosition()\n",
    "                objPosPoint_l = p_obj_world\n",
    "                \n",
    "            else:\n",
    "                #images from the cart camera\n",
    "                S.selectSensor(\"cart_camera\")\n",
    "                [rgb, depth] = S.getImageAndDepth()\n",
    "                bgr = cv.cvtColor(rgb, cv.COLOR_RGB2BGR)\n",
    "                hsv = cv.cvtColor(bgr, cv.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "                global objPosPoint_cart\n",
    "                masked, p_obj_rel = findObstaclePoints(hsv, depth)\n",
    "\n",
    "                # Coordinate conversion from camera frame to world frame\n",
    "                obj = RealWorld.addFrame(\"object\", \"cart_camera\")\n",
    "                obj.setRelativePosition(p_obj_rel)\n",
    "                p_obj_world = obj.getPosition()\n",
    "                objPosPoint_cart = p_obj_world\n",
    "            \n",
    "\n",
    "            V.recopyMeshes(RealWorld)\n",
    "            V.setConfiguration(RealWorld)\n",
    "\n",
    "            #if len(bgr)>0: cv.imshow(\"OPENCV - bgr\", bgr) #to print the bgr contours\n",
    "            #if len(hsv)>0: cv.imshow(\"OPENCV - hsv\", hsv) #to print the hsv contours\n",
    "            if len(masked)>0: cv.imshow(\"OPENCV - mask\", masked) # to print the mask\n",
    "\n",
    "            if cv.waitKey(1) & 0xFF == ord(\"q\"): break\n",
    "        S.step([], tau, ry.ControlMode.none)\n",
    "\n",
    "\n",
    "# Gets the mean position of the most right positioned object in the camera image (given the defined color in \"itemColor\")\n",
    "# and relative to the camera frame!.\n",
    "def findObjPointPos(hsv, depth):\n",
    "    x_value = None\n",
    "    y_value = None\n",
    "    mask = None\n",
    "\n",
    "    # Creates thresholds for the colour red based on that a mask of all the red objects in the given camera image.\n",
    "    if itemColor[0] == \"red\":\n",
    "        lower_red1 = np.array([0,50,20])\n",
    "        upper_red1 = np.array([5,255,255])\n",
    "        lower_red2 = np.array([175,50,20])\n",
    "        upper_red2 = np.array([180,255,255])\n",
    "\n",
    "        hue = hsv[:,:,0]\n",
    "        sat = hsv[:,:,1]\n",
    "        val = hsv[:,:,2]\n",
    "        \n",
    "        # Get all red pixels with their x and y values\n",
    "        pixel_is_red = np.logical_and(np.logical_or(hue < 16, hue > 164), sat > 150, val > 150)\n",
    "        x_value, y_value = np.where(pixel_is_red)\n",
    "        \n",
    "        # Create a mask (an image where all red pixels are colored white and all the others black)\n",
    "        mask1 = cv.inRange(hsv, lower_red1, upper_red1)\n",
    "        mask2 = cv.inRange(hsv, lower_red2, upper_red2)\n",
    "        mask = mask1 + mask2\n",
    "    \n",
    "    # Creates thresholds for the colours blue or green based on that a mask of all the blue (or green) objects in the given camera image.\n",
    "    elif itemColor[0] == \"blue\":\n",
    "        # define range of blue colour in HSV\n",
    "        lower_blue = np.array([110,50,50])\n",
    "        upper_blue = np.array([130,255,255])\n",
    "        \n",
    "        # Create a mask (an image where all color pixels are colored white and all the others black)\n",
    "        mask = cv.inRange(hsv, lower_blue, upper_blue)\n",
    "        \n",
    "    elif itemColor[0] == \"green\":\n",
    "        # define range of green colour in HSV\n",
    "        lower_green = np.array([25,52,72])\n",
    "        upper_green = np.array([102,255,255])\n",
    "        \n",
    "        # Create a mask (an image where all color pixels are colored white and all the others black)\n",
    "        mask = cv.inRange(hsv, lower_green, upper_green)\n",
    "    \n",
    "    else:\n",
    "        print(\"Wrong Item Color\")\n",
    "\n",
    "    # create empty mask\n",
    "    filtered_mask = np.zeros(mask.shape, np.uint8)\n",
    "    # find contours\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # Draws the contours (i.e. the complete area) of the object with index 0 in contours list, i.e. the object that is the most right in the image.\n",
    "    cv.drawContours(filtered_mask, contours, 0, (255,255,255),-1)\n",
    "    # Get the point cloud of the object in the mask in image coordinates\n",
    "    objPixelPointCloud = image_to_pointcloud(depth, filtered_mask)\n",
    "    # Transforms the pount cloud (pixel points) into meters (but still relative to the camera frame)\n",
    "    obj_points = meter_pointcloud(objPixelPointCloud, fxfypxpy)\n",
    "    # Computes the mean\n",
    "    p_obj_rel = np.mean(obj_points, axis=0)\n",
    "\n",
    "    return mask, p_obj_rel\n",
    "\n",
    "# Gets the point cloud of the object in image coordinates.\n",
    "# Retrieves an array containing the x, y coordinates from the object mask and the corresponding x, y coordinates (depth-meters) from the depth image \n",
    "def image_to_pointcloud(depth, mask):\n",
    "    mask_pixels = np.where(mask>0)\n",
    "    pointcloud = np.empty((mask_pixels[0].shape[0], 3))\n",
    "    pointcloud[:,0] = mask_pixels[1]  # x pixels\n",
    "    pointcloud[:,1] = mask_pixels[0]  # y pixels\n",
    "    pointcloud[:,2] = depth[mask_pixels[0], mask_pixels[1]]\n",
    "    return pointcloud\n",
    "\n",
    "# Transforms the point cloud (pixel points from the camera image) into meters with the camera preferences (to get the real point cloud positions in 3D space).\n",
    "def meter_pointcloud(pixel_points, fxfypxpy):\n",
    "    points = np.empty(np.shape(pixel_points))\n",
    "    for i, p in enumerate(pixel_points):\n",
    "        x = p[0]\n",
    "        y = p[1]\n",
    "        d = p[2]\n",
    "        \n",
    "        px = fxfypxpy[-2]\n",
    "        py = fxfypxpy[-1]\n",
    "        \n",
    "        x_ =  d * (x-px) / fxfypxpy[0]\n",
    "        y_ = -d * (y-py) / fxfypxpy[1]\n",
    "        z_ = -d\n",
    "        points[i] = [x_,y_,z_]\n",
    "    return points\n",
    "\n",
    "# Retrieves the mean point of all the object points of the obstacle (relative to the camera frame!).\n",
    "# This only uses red color detection, so the obstacle needs to be red in order to detect it!\n",
    "def findObstaclePoints(hsv, depth):\n",
    "    lower_red1 = np.array([0,50,20])\n",
    "    upper_red1 = np.array([5,255,255])\n",
    "    lower_red2 = np.array([175,50,20])\n",
    "    upper_red2 = np.array([180,255,255])\n",
    "\n",
    "    hue = hsv[:,:,0]\n",
    "    sat = hsv[:,:,1]\n",
    "    val = hsv[:,:,2]\n",
    "\n",
    "    pixel_is_red = np.logical_and(np.logical_or(hue < 16, hue > 164), sat > 150, val > 150)\n",
    "    x_value, y_value = np.where(pixel_is_red)\n",
    "    \n",
    "    # Create a mask (an image where all red pixels are colored white and all the others black)\n",
    "    mask1 = cv.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = mask1 + mask2\n",
    "    \n",
    "    # create empty mask\n",
    "    filtered_mask = np.zeros(mask.shape, np.uint8)\n",
    "    # find contours\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    # Draws the contours (i.e. the complete area) of the obstacle.\n",
    "    cv.drawContours(filtered_mask, contours, 0, (255,255,255),-1)\n",
    "    # Get the point cloud of the object in the mask in image coordinates\n",
    "    objPixelPointCloud = image_to_pointcloud(depth, filtered_mask)\n",
    "    # Transforms the pount cloud (pixel points) into meters (but still relative to the camera frame)\n",
    "    obj_points = meter_pointcloud(objPixelPointCloud, fxfypxpy)\n",
    "    # Computes the mean\n",
    "    p_obj_rel = np.mean(obj_points, axis=0)\n",
    "\n",
    "    return mask, p_obj_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for color-segmentation for each-shelf, to return the object colors as a lsit (input for the method-Shopping())\n",
    "def colorSeg(selCamera):\n",
    "    points = []\n",
    "    colorList = [0] * 3  # order of the colorlist is RGB\n",
    "    colors = []\n",
    "    font = cv.FONT_HERSHEY_COMPLEX\n",
    "    \n",
    "    if selCamera == \"lcam\":\n",
    "        S.addSensor(\"l_camera\")\n",
    "    else:\n",
    "        S.addSensor(\"r_camera\")\n",
    "\n",
    "    [rgb, depth] = S.getImageAndDepth()\n",
    "\n",
    "    hsvFrame = cv.cvtColor(rgb, cv.COLOR_RGB2HSV) \n",
    "    \n",
    "    \n",
    "    # define range of blue colour in HSV\n",
    "    blue_lower = np.array([110,50,50], np.uint8) \n",
    "    blue_upper = np.array([130, 255, 255], np.uint8) \n",
    "    blue_mask = cv.inRange(hsvFrame, blue_lower, blue_upper) \n",
    "    \n",
    "    # define range of green colour in HSV\n",
    "    green_lower = np.array([25, 52, 72], np.uint8) \n",
    "    green_upper = np.array([102, 255, 255], np.uint8) \n",
    "    green_mask = cv.inRange(hsvFrame, green_lower, green_upper) \n",
    "    \n",
    "    # define range of red colour in HSV\n",
    "    red_lower = np.array([0, 50, 50], np.uint8) \n",
    "    red_upper = np.array([10, 255, 255], np.uint8) \n",
    "    red_mask = cv.inRange(hsvFrame, red_lower, red_upper) \n",
    "    kernal = np.ones((5, 5), \"uint8\") \n",
    "    \n",
    "    \n",
    "    #creating masks of blue color\n",
    "    blue_mask = cv.dilate(blue_mask, kernal) \n",
    "    res_blue = cv.bitwise_and(rgb, rgb,  \n",
    "                              mask = blue_mask) \n",
    "    #creating masks of green color\n",
    "    green_mask = cv.dilate(green_mask, kernal) \n",
    "    res_green = cv.bitwise_and(rgb, rgb, \n",
    "                                mask = green_mask) \n",
    "    #creating masks of red color\n",
    "    red_mask = cv.dilate(red_mask, kernal) \n",
    "    res_red = cv.bitwise_and(rgb, rgb, \n",
    "                               mask = red_mask)\n",
    "\n",
    "    # Creating contour to track blue color \n",
    "    contours, hierarchy = cv.findContours(blue_mask, \n",
    "                                           cv.RETR_TREE, \n",
    "                                           cv.CHAIN_APPROX_SIMPLE) \n",
    "    for pic, contour in enumerate(contours): \n",
    "        colorList[2]= colorList[2] + 1\n",
    "\n",
    "\n",
    "    # Creating contour to track green color \n",
    "    contours, hierarchy = cv.findContours(green_mask, \n",
    "                                           cv.RETR_TREE, \n",
    "                                           cv.CHAIN_APPROX_SIMPLE) \n",
    "    for pic, contour in enumerate(contours): \n",
    "        colorList[1]= colorList[1] + 1\n",
    "\n",
    "    # Creating contour to track red color \n",
    "    contours, hierarchy = cv.findContours(red_mask, \n",
    "                                           cv.RETR_TREE, \n",
    "                                           cv.CHAIN_APPROX_SIMPLE) \n",
    "    #based on the colors of the contours, adding the colors into a list, to determine the order of the objects on the shelf\n",
    "    for pic, contour in enumerate(contours): \n",
    "        colorList[0]= colorList[0] + 1\n",
    "\n",
    "    return colorList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy():\n",
    "        S = 0\n",
    "        RealWorld = 0\n",
    "        V = 0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers = [0]*4\n",
    "#GUI for user interaction\n",
    "sg.theme('DefaultNoMoreNagging')   # Add a touch of color\n",
    "background = '#F0F0F0'\n",
    "# All the stuff inside the window.\n",
    "layout = [  [sg.Text('Welcome to RoboKart: Robot-Assisted shopping experience!',font=(\"ComicSansMS\", 12))],\n",
    "            [sg.Text('Please fill in the shopping cart!',font=(\"ComicSansMS\", 12))],\n",
    "            [sg.Button('Green:', size=(8, 1), button_color=('Black', 'Green'),font=(\"ComicSansMS\", 12)), sg.InputText()],\n",
    "            [sg.Button('Blue:', size=(8, 1),button_color=('Black', 'Blue'),font=(\"ComicSansMS\", 12)), sg.InputText()],\n",
    "            [sg.Button('Red:', size=(8, 1),button_color=('Black', 'Red'),font=(\"ComicSansMS\", 12)), sg.InputText()],\n",
    "            [sg.Button('Pink:', size=(8, 1),button_color=('Black', 'Pink'),font=(\"ComicSansMS\", 12)), sg.InputText()],\n",
    "            [sg.Submit(button_color=('Black', 'White'),font=(\"ComicSansMS\", 12)), sg.Cancel(button_color=('White', 'Black'),font=(\"ComicSansMS\", 12))]]\n",
    "\n",
    "# Create the Window\n",
    "window = sg.Window('Hello_from_Anja_Gunjan', layout)\n",
    "event, values = window.read()\n",
    "\n",
    "window.close()\n",
    "print('--------------------------------------------')\n",
    "print('                 Display                    ')\n",
    "print('--------------------------------------------')\n",
    "\n",
    "#to display on the terminal\n",
    "print('Number of Green Objects:', values[0])\n",
    "numbers[0]=int(values[0])\n",
    "print('Number of Blue Objects:', values[1])\n",
    "numbers[1]=int(values[1])\n",
    "print('Number of Red Objects:', values[2])\n",
    "numbers[2]=int(values[2])\n",
    "print('Number of Pink Objects:',values[3])\n",
    "numbers[3]=int(values[3])\n",
    "\n",
    "#to run the final code\n",
    "colors= ['green','blue','red','pink']\n",
    "count = 0\n",
    "for i in range(0, len(numbers)):\n",
    "    count = count + numbers[i]\n",
    "shopping(colors, numbers, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
